{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats Vs Dogs Image Binary Classification\n",
    "## Demonstrates Data Augmentation and Transfer Learning\n",
    "\n",
    "### [Partly derived from Tutorial by Laurence Moroney](https://www.tensorflow.org/tutorials/images/classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow module. Check API version.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print (tf.__version__)\n",
    "\n",
    "# required for TF to run within docker using GPU (ignore otherwise)\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image Data with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define training data augmentation pipeline\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255.,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# load training data\n",
    "TRAINING_DIR = '../data/deep_learning/cats-and-dogs/training/'\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=128,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "# define validation data augmentation pipeline\n",
    "validation_datagen = ImageDataGenerator( rescale = 1.0/255.,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# load validation data\n",
    "VALIDATION_DIR = '../data/deep_learning/cats-and-dogs/testing/'\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                         batch_size=128,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Compile CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Conv Layer 1\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    # Conv Layer 2\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Conv Layer 3\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Conv Layer 4\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # FC layer 1\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "\n",
    "    # FC layer 2\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callback function for training termination criteria\n",
    "#accuracy_cutoff = 0.99\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    if(logs.get('accuracy') > 0.90):\n",
    "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# initialize training config\n",
    "epochs = 100\n",
    "\n",
    "# run training\n",
    "print(\"[INFO] training...\")\n",
    "history = model.fit(train_generator, validation_data=validation_generator,\n",
    "                    epochs=epochs, verbose=1, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Training Performance\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "![accplot](images/accuracyCatsVsDogs.png) ![lossplot](images/lossCatsVsDogs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# retrieve a list of list results on training and test data sets for each training epoch\n",
    "acc      = history.history['accuracy']\n",
    "val_acc  = history.history['val_accuracy']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs   = range(len(acc)) # get number of epochs\n",
    "\n",
    "# plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc, label='train accuracy')\n",
    "plt.plot(epochs, val_acc, label='val accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "# plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss, label='train loss')\n",
    "plt.plot(epochs, val_loss, label='val loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Demo\n",
    "\n",
    "## Load Pre-Trained Inception V3 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
    "                                include_top = False,\n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_weights_file = '../data/deep_learning/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model.load_weights(pre_trained_weights_file)\n",
    "\n",
    "pre_trained_model.trainable = False\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract part of Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output = pre_trained_model.get_layer('mixed10').output\n",
    "\n",
    "base_model = tf.keras.Model(pre_trained_model.input, last_output)\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extent Base Model with Own Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "extended_model = tf.keras.Sequential([\n",
    "    # base model (part of Inception V3)\n",
    "    base_model,\n",
    "    \n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(), \n",
    "\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "\n",
    "    # Only 1 output neuron.\n",
    "    # It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "extended_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "# print model summary\n",
    "extended_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callback function for training termination criteria\n",
    "#accuracy_cutoff = 0.99\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    if(logs.get('accuracy') > 0.90):\n",
    "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# initialize training config\n",
    "epochs = 30\n",
    "\n",
    "# run training\n",
    "print(\"[INFO] training...\")\n",
    "history = extended_model.fit(train_generator, validation_data=validation_generator,\n",
    "                    epochs=epochs, verbose=1, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
