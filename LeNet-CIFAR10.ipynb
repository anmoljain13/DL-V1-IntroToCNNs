{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using LeNet CNN\n",
    "## CIFAR-10 Dataset - Animals and Objects (10 classes)\n",
    "\n",
    "![CIFAR10 Sample Data](images/CIFAR10Examples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow module. Check API version.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print (tf.__version__)\n",
    "\n",
    "# required for TF to run within docker using GPU (ignore otherwise)\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the CIFAR-10 dataset (may take time the first time)\n",
    "print(\"[INFO] downloading CIFAR-10...\")\n",
    "((trainData, trainLabels), (testData, testLabels)) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for CIFAR-10 data set\n",
    "num_classes = 10\n",
    "image_width = 32\n",
    "image_height = 32\n",
    "image_channels = 3 # CIFAR data is RGB color\n",
    "# define human readable class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', \n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the input data using \"channels last\" ordering\n",
    "# num_samples x rows x columns x depth\n",
    "trainData = trainData.reshape(\n",
    "        (trainData.shape[0], image_height, image_width, image_channels))\n",
    "testData = testData.reshape(\n",
    "        (testData.shape[0], image_height, image_width, image_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to floating point and scale data to the range of [0.0, 1.0]\n",
    "trainData = trainData.astype(\"float32\") / 255.0\n",
    "testData = testData.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display data dimentions\n",
    "print (\"trainData:\", trainData.shape)\n",
    "print (\"trainLabels:\", trainLabels.shape)\n",
    "print (\"testData:\", testData.shape)\n",
    "print (\"testLabels:\", testLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "![LeNet5 Model](images/LeNet5.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# define the model as a class\n",
    "class LeNet:\n",
    "    # INPUT => CONV => TANH => AVG-POOL => CONV => TANH => AVG-POOL => FC => TANH => FC => TANH => FC => SMAX\n",
    "    @staticmethod\n",
    "    def init(numChannels, imgRows, imgCols, numClasses, weightsPath=None):\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if backend.image_data_format() == \"channels_first\":\n",
    "            inputShape = (numChannels, imgRows, imgCols)\n",
    "        else:  # \"channels last\"\n",
    "            inputShape = (imgRows, imgCols, numChannels)\n",
    "\n",
    "        # initialize the model\n",
    "        model = models.Sequential()\n",
    "\n",
    "        # define the first set of CONV => ACTIVATION => POOL layers\n",
    "        model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1),\n",
    "                padding=\"valid\", activation=tf.nn.tanh, input_shape=inputShape))\n",
    "        model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # define the second set of CONV => ACTIVATION => POOL layers\n",
    "        model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1),\n",
    "                padding=\"valid\", activation=tf.nn.tanh))\n",
    "        model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # flatten the convolution volume to fully connected layers\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        # define the first FC => ACTIVATION layers\n",
    "        model.add(layers.Dense(units=120, activation=tf.nn.tanh))\n",
    "\n",
    "        # define the second FC => ACTIVATION layers\n",
    "        model.add(layers.Dense(units=84, activation=tf.nn.tanh))\n",
    "\n",
    "        # lastly, define the soft-max classifier\n",
    "        model.add(layers.Dense(units=numClasses, activation=tf.nn.softmax))\n",
    "\n",
    "        # if a weights path is supplied (inicating that the model was\n",
    "        # pre-trained), then load the weights\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.init(numChannels=image_channels,\n",
    "                    imgRows=image_height, imgCols=image_width,\n",
    "                    numClasses=num_classes,\n",
    "                    weightsPath=None)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),  # Adam optimizer\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callback function for training termination criteria\n",
    "#accuracy_cutoff = 0.99\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    if(logs.get('accuracy') > 0.90):\n",
    "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# initialize training config\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "# run training\n",
    "print(\"[INFO] training...\")\n",
    "history = model.fit(x=trainData, y=trainLabels, batch_size=batch_size,\n",
    "                    validation_data=(testData, testLabels), epochs=epochs, verbose=1, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Training Performance\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "![accplot](images/accuracyLeNetCIFAR10.png) ![lossplot](images/lossLeNetCIFAR10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# retrieve a list of list results on training and test data sets for each training epoch\n",
    "acc      = history.history['accuracy']\n",
    "val_acc  = history.history['val_accuracy']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs   = range(len(acc)) # get number of epochs\n",
    "\n",
    "# plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc, label='train accuracy')\n",
    "plt.plot(epochs, val_acc, label='val accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "# plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss, label='train loss')\n",
    "plt.plot(epochs, val_loss, label='val loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels,\n",
    "                                  batch_size=batch_size, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights/LeNetCIFAR10.temp.hdf5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model and load the model weights\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.init(numChannels=image_channels, \n",
    "                    imgRows=image_height, imgCols=image_width,\n",
    "                    numClasses=num_classes,\n",
    "                    weightsPath=\"weights/LeNetCIFAR10.hdf5\")\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01),  # Stochastic Gradient Descent\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating...\")\n",
    "batch_size = 128\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels,\n",
    "                                  batch_size=batch_size, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up matplotlib fig, and size it to fit 3x4 pics\n",
    "nrows = 3\n",
    "ncols = 4\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "# randomly select a few testing digits\n",
    "num_predictions = 12\n",
    "test_indices = np.random.choice(np.arange(0, len(testLabels)), size=(num_predictions,))\n",
    "test_images = np.stack(([testData[i] for i in test_indices]))\n",
    "test_labels = np.stack(([testLabels[i] for i in test_indices]))\n",
    "\n",
    "# compute predictions\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "for i in range(num_predictions):\n",
    "    # select the most probable class\n",
    "    prediction = np.argmax(predictions[i])\n",
    "\n",
    "    # rescale the test image\n",
    "    image = (test_images[i] * 255).astype(\"uint8\")\n",
    "\n",
    "    # resize the image from a 32 X 32 image to a 96 x 96 image so we can better see it\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # select prediction text color\n",
    "    if prediction == test_labels[i]:\n",
    "        rgb_color = (0, 255, 0) # green for correct predictions\n",
    "    else:\n",
    "        rgb_color = (255, 0, 0) # red for wrong predictions\n",
    "\n",
    "    # show the image and prediction\n",
    "    cv2.putText(image, str(class_names[prediction]), (0, 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, rgb_color, 1)\n",
    "    \n",
    "    # set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1, title=\"label: %s\" % class_names[test_labels[i][0]])\n",
    "    sp.axis('Off') # don't show axes (or gridlines)\n",
    "    plt.imshow(image)\n",
    "\n",
    "# show figure matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
